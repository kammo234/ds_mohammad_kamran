{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLuLnuWFlzNk"
      },
      "source": [
        "# Notebook 2 — Modeling, Hypothesis Tests, and Signal Discovery\n",
        "\n",
        "**Candidate:** Mohammad_Kamran  \n",
        "**Date:** 2025-08-29\n",
        "\n",
        "This notebook:\n",
        "1. Loads the merged data from Notebook 1.  \n",
        "2. Runs statistical tests comparing *Fear* vs *Greed*.  \n",
        "3. Trains predictive models for *probability of a winning trade*.  \n",
        "4. Explores account clusters and leverage-size regimes.  \n",
        "5. Performs an **event study** around Fear↔Greed regime changes.\n"
      ],
      "id": "vLuLnuWFlzNk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZSIKiz0lzNq"
      },
      "execution_count": 1,
      "outputs": [],
      "source": [
        "# !pip -q install pandas numpy matplotlib scipy statsmodels scikit-learn plotly\n",
        "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "id": "lZSIKiz0lzNq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoaUn_3MlzNt",
        "outputId": "5bc5dd30-1c13-4721-a596-0bfc861d7d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'csv_files/trades_with_sentiment.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2068271232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCSV_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"csv_files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmerged_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trades_with_sentiment.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trade_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Basic sanitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'csv_files/trades_with_sentiment.csv'"
          ]
        }
      ],
      "source": [
        "CSV_DIR = \"csv_files\"\n",
        "merged_path = os.path.join(CSV_DIR, \"trades_with_sentiment.csv\")\n",
        "df = pd.read_csv(merged_path, parse_dates=[\"trade_date\"], low_memory=False)\n",
        "\n",
        "# Basic sanitation\n",
        "df[\"win\"] = (df.get(\"closed_pnl\", 0) > 0).astype(int)\n",
        "\n",
        "# Encode sentiment\n",
        "df[\"is_greed\"] = (df[\"sentiment\"].str.lower()==\"greed\").astype(int)\n",
        "df[\"is_fear\"]  = (df[\"sentiment\"].str.lower()==\"fear\").astype(int)\n",
        "\n",
        "# Fill leverage/size with medians to avoid NaNs for modeling\n",
        "for col in [\"leverage\", \"size\"]:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "    else:\n",
        "        df[col] = 0.0\n",
        "\n",
        "# Side encoding\n",
        "df[\"side_long\"]  = (df.get(\"side\",\"\").astype(str).str.lower().str.contains(\"buy|long\")).astype(int)\n",
        "df[\"side_short\"] = (df.get(\"side\",\"\").astype(str).str.lower().str.contains(\"sell|short\")).astype(int)\n"
      ],
      "id": "MoaUn_3MlzNt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsCj7-PalzNu"
      },
      "source": [
        "## 1) Hypothesis tests (Fear vs Greed)\n"
      ],
      "id": "YsCj7-PalzNu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RRTijOnlzNu"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Compare win_rate between Fear vs Greed\n",
        "win_fear  = df.loc[df[\"is_fear\"]==1, \"win\"].dropna()\n",
        "win_greed = df.loc[df[\"is_greed\"]==1, \"win\"].dropna()\n",
        "t_stat, p_val = stats.ttest_ind(win_fear, win_greed, equal_var=False, nan_policy=\"omit\")\n",
        "print(\"Win-rate t-test Fear vs Greed: t=%.3f  p=%.3g\" % (t_stat, p_val))\n",
        "\n",
        "# Compare leverage\n",
        "lev_fear  = df.loc[df[\"is_fear\"]==1, \"leverage\"].dropna()\n",
        "lev_greed = df.loc[df[\"is_greed\"]==1, \"leverage\"].dropna()\n",
        "t_stat2, p_val2 = stats.ttest_ind(lev_fear, lev_greed, equal_var=False, nan_policy=\"omit\")\n",
        "print(\"Leverage t-test Fear vs Greed: t=%.3f  p=%.3g\" % (t_stat2, p_val2))\n"
      ],
      "id": "4RRTijOnlzNu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpANic_YlzNv"
      },
      "source": [
        "## 2) Predictive modeling: P(win) ~ sentiment + leverage + size + side\n"
      ],
      "id": "BpANic_YlzNv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_8K4PqDlzNw"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "features = [\"is_greed\", \"leverage\", \"size\", \"side_long\", \"side_short\"]\n",
        "X = df[features].copy()\n",
        "y = df[\"win\"].astype(int).copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# Logistic Regression\n",
        "logit = LogisticRegression(max_iter=200)\n",
        "logit.fit(X_train, y_train)\n",
        "proba = logit.predict_proba(X_test)[:,1]\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "print(\"Logit AUC:\", round(auc, 4))\n",
        "print(classification_report(y_test, (proba>0.5).astype(int)))\n",
        "\n",
        "# Random Forest (nonlinear interactions)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "proba_rf = rf.predict_proba(X_test)[:,1]\n",
        "auc_rf = roc_auc_score(y_test, proba_rf)\n",
        "print(\"RF AUC:\", round(auc_rf, 4))\n"
      ],
      "id": "D_8K4PqDlzNw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAVUiO2dlzNw"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Feature importances\n",
        "imp = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=False)\n",
        "print(imp)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "imp.plot(kind=\"bar\", ax=ax)\n",
        "ax.set_title(\"Random Forest Feature Importances\")\n",
        "fig.tight_layout()\n",
        "fig.savefig(os.path.join(\"outputs\",\"rf_feature_importances.png\"), dpi=160)\n"
      ],
      "id": "gAVUiO2dlzNw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju14R_5vlzNx"
      },
      "source": [
        "## 3) Account clusters (behavioral archetypes)\n"
      ],
      "id": "Ju14R_5vlzNx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfL7MN-qlzNy"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Build per-account features from Notebook 1 outputs if available\n",
        "acct_path = os.path.join(\"csv_files\",\"account_kpis_wide.csv\")\n",
        "acct = pd.read_csv(acct_path) if os.path.exists(acct_path) else None\n",
        "if acct is not None:\n",
        "    acct = acct.set_index(\"account\")\n",
        "    Xacct = acct.fillna(0.0).copy()\n",
        "    Z = StandardScaler().fit_transform(Xacct)\n",
        "    km = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
        "    labels = km.fit_predict(Z)\n",
        "    acct[\"cluster\"] = labels\n",
        "    acct.to_csv(os.path.join(\"csv_files\",\"account_clusters.csv\"))\n",
        "    display(acct.groupby(\"cluster\").mean())\n",
        "else:\n",
        "    print(\"Run Notebook 1 to generate account_kpis_wide.csv first.\")\n"
      ],
      "id": "OfL7MN-qlzNy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAtPPfnelzNz"
      },
      "source": [
        "## 4) Event study around regime changes\n",
        "Define Fear→Greed and Greed→Fear switches, then measure average PnL before/after.\n"
      ],
      "id": "kAtPPfnelzNz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOYlt-nllzNz"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Build sentiment series\n",
        "sent = df[[\"trade_date\",\"sentiment\"]].drop_duplicates().sort_values(\"trade_date\")\n",
        "sent[\"is_greed\"] = (sent[\"sentiment\"].str.lower()==\"greed\").astype(int)\n",
        "sent = sent.set_index(\"trade_date\").asfreq(\"D\").ffill().reset_index()\n",
        "\n",
        "# Identify change points\n",
        "sent[\"prev\"] = sent[\"is_greed\"].shift(1)\n",
        "sent[\"chg\"] = sent[\"is_greed\"] - sent[\"prev\"]  # +1 fear->greed ; -1 greed->fear\n",
        "cp = sent[sent[\"chg\"].isin([1,-1])][\"trade_date\"].tolist()\n",
        "\n",
        "def window_pnl(center_date, days=3):\n",
        "    w = df[(df[\"trade_date\"]>=center_date-pd.Timedelta(days=days)) &\n",
        "           (df[\"trade_date\"]<=center_date+pd.Timedelta(days=days))]\n",
        "    agg = w.groupby(\"trade_date\")[\"closed_pnl\"].mean().reset_index()\n",
        "    agg[\"rel_day\"] = (agg[\"trade_date\"] - center_date).dt.days\n",
        "    return agg[[\"rel_day\",\"closed_pnl\"]]\n",
        "\n",
        "# Aggregate event windows\n",
        "all_win = []\n",
        "for d in cp:\n",
        "    all_win.append(window_pnl(d, days=3))\n",
        "if all_win:\n",
        "    ev = pd.concat(all_win, ignore_index=True)\n",
        "    evg = ev.groupby(\"rel_day\")[\"closed_pnl\"].mean().reset_index()\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(evg[\"rel_day\"], evg[\"closed_pnl\"], marker=\"o\")\n",
        "    ax.axvline(0, linestyle=\"--\")\n",
        "    ax.set_title(\"Event Study: Avg Closed PnL around Sentiment Regime Switches\")\n",
        "    ax.set_xlabel(\"Days from Switch\")\n",
        "    ax.set_ylabel(\"Avg Closed PnL\")\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(\"outputs\",\"event_study_pnl.png\"), dpi=160)\n",
        "else:\n",
        "    print(\"No regime switches found (check sentiment coverage).\")\n"
      ],
      "id": "QOYlt-nllzNz"
    }
  ],
  "metadata": {
    "colab": {
      "name": "notebook_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}