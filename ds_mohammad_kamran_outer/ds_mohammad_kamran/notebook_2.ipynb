{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Notebook 2 — Modeling, Hypothesis Tests, and Signal Discovery\n\n**Candidate:** Mohammad_Kamran  \n**Date:** 2025-08-29\n\nThis notebook:\n1. Loads the merged data from Notebook 1.  \n2. Runs statistical tests comparing *Fear* vs *Greed*.  \n3. Trains predictive models for *probability of a winning trade*.  \n4. Explores account clusters and leverage-size regimes.  \n5. Performs an **event study** around Fear↔Greed regime changes.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# !pip -q install pandas numpy matplotlib scipy statsmodels scikit-learn plotly\nimport os, numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "CSV_DIR = \"csv_files\"\nmerged_path = os.path.join(CSV_DIR, \"trades_with_sentiment.csv\")\ndf = pd.read_csv(merged_path, parse_dates=[\"trade_date\"], low_memory=False)\n\n# Basic sanitation\ndf[\"win\"] = (df.get(\"closed_pnl\", 0) > 0).astype(int)\n\n# Encode sentiment\ndf[\"is_greed\"] = (df[\"sentiment\"].str.lower()==\"greed\").astype(int)\ndf[\"is_fear\"]  = (df[\"sentiment\"].str.lower()==\"fear\").astype(int)\n\n# Fill leverage/size with medians to avoid NaNs for modeling\nfor col in [\"leverage\", \"size\"]:\n    if col in df.columns:\n        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n        df[col] = df[col].fillna(df[col].median())\n    else:\n        df[col] = 0.0\n\n# Side encoding\ndf[\"side_long\"]  = (df.get(\"side\",\"\").astype(str).str.lower().str.contains(\"buy|long\")).astype(int)\ndf[\"side_short\"] = (df.get(\"side\",\"\").astype(str).str.lower().str.contains(\"sell|short\")).astype(int)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Hypothesis tests (Fear vs Greed)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Compare win_rate between Fear vs Greed\nwin_fear  = df.loc[df[\"is_fear\"]==1, \"win\"].dropna()\nwin_greed = df.loc[df[\"is_greed\"]==1, \"win\"].dropna()\nt_stat, p_val = stats.ttest_ind(win_fear, win_greed, equal_var=False, nan_policy=\"omit\")\nprint(\"Win-rate t-test Fear vs Greed: t=%.3f  p=%.3g\" % (t_stat, p_val))\n\n# Compare leverage\nlev_fear  = df.loc[df[\"is_fear\"]==1, \"leverage\"].dropna()\nlev_greed = df.loc[df[\"is_greed\"]==1, \"leverage\"].dropna()\nt_stat2, p_val2 = stats.ttest_ind(lev_fear, lev_greed, equal_var=False, nan_policy=\"omit\")\nprint(\"Leverage t-test Fear vs Greed: t=%.3f  p=%.3g\" % (t_stat2, p_val2))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Predictive modeling: P(win) ~ sentiment + leverage + size + side\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "features = [\"is_greed\", \"leverage\", \"size\", \"side_long\", \"side_short\"]\nX = df[features].copy()\ny = df[\"win\"].astype(int).copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n\n# Logistic Regression\nlogit = LogisticRegression(max_iter=200)\nlogit.fit(X_train, y_train)\nproba = logit.predict_proba(X_test)[:,1]\nauc = roc_auc_score(y_test, proba)\nprint(\"Logit AUC:\", round(auc, 4))\nprint(classification_report(y_test, (proba>0.5).astype(int)))\n\n# Random Forest (nonlinear interactions)\nrf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\nrf.fit(X_train, y_train)\nproba_rf = rf.predict_proba(X_test)[:,1]\nauc_rf = roc_auc_score(y_test, proba_rf)\nprint(\"RF AUC:\", round(auc_rf, 4))\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Feature importances\nimp = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=False)\nprint(imp)\nfig = plt.figure()\nax = fig.add_subplot(111)\nimp.plot(kind=\"bar\", ax=ax)\nax.set_title(\"Random Forest Feature Importances\")\nfig.tight_layout()\nfig.savefig(os.path.join(\"outputs\",\"rf_feature_importances.png\"), dpi=160)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Account clusters (behavioral archetypes)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n\n# Build per-account features from Notebook 1 outputs if available\nacct_path = os.path.join(\"csv_files\",\"account_kpis_wide.csv\")\nacct = pd.read_csv(acct_path) if os.path.exists(acct_path) else None\nif acct is not None:\n    acct = acct.set_index(\"account\")\n    Xacct = acct.fillna(0.0).copy()\n    Z = StandardScaler().fit_transform(Xacct)\n    km = KMeans(n_clusters=4, random_state=42, n_init=10)\n    labels = km.fit_predict(Z)\n    acct[\"cluster\"] = labels\n    acct.to_csv(os.path.join(\"csv_files\",\"account_clusters.csv\"))\n    display(acct.groupby(\"cluster\").mean())\nelse:\n    print(\"Run Notebook 1 to generate account_kpis_wide.csv first.\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Event study around regime changes\nDefine Fear→Greed and Greed→Fear switches, then measure average PnL before/after.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Build sentiment series\nsent = df[[\"trade_date\",\"sentiment\"]].drop_duplicates().sort_values(\"trade_date\")\nsent[\"is_greed\"] = (sent[\"sentiment\"].str.lower()==\"greed\").astype(int)\nsent = sent.set_index(\"trade_date\").asfreq(\"D\").ffill().reset_index()\n\n# Identify change points\nsent[\"prev\"] = sent[\"is_greed\"].shift(1)\nsent[\"chg\"] = sent[\"is_greed\"] - sent[\"prev\"]  # +1 fear->greed ; -1 greed->fear\ncp = sent[sent[\"chg\"].isin([1,-1])][\"trade_date\"].tolist()\n\ndef window_pnl(center_date, days=3):\n    w = df[(df[\"trade_date\"]>=center_date-pd.Timedelta(days=days)) & \n           (df[\"trade_date\"]<=center_date+pd.Timedelta(days=days))]\n    agg = w.groupby(\"trade_date\")[\"closed_pnl\"].mean().reset_index()\n    agg[\"rel_day\"] = (agg[\"trade_date\"] - center_date).dt.days\n    return agg[[\"rel_day\",\"closed_pnl\"]]\n\n# Aggregate event windows\nall_win = []\nfor d in cp:\n    all_win.append(window_pnl(d, days=3))\nif all_win:\n    ev = pd.concat(all_win, ignore_index=True)\n    evg = ev.groupby(\"rel_day\")[\"closed_pnl\"].mean().reset_index()\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.plot(evg[\"rel_day\"], evg[\"closed_pnl\"], marker=\"o\")\n    ax.axvline(0, linestyle=\"--\")\n    ax.set_title(\"Event Study: Avg Closed PnL around Sentiment Regime Switches\")\n    ax.set_xlabel(\"Days from Switch\")\n    ax.set_ylabel(\"Avg Closed PnL\")\n    fig.tight_layout()\n    fig.savefig(os.path.join(\"outputs\",\"event_study_pnl.png\"), dpi=160)\nelse:\n    print(\"No regime switches found (check sentiment coverage).\")\n"
    }
  ],
  "metadata": {
    "colab": {
      "name": "notebook_2.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}